{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Covid Data Prep</h1>\n",
    "<h3>Feature Engineering</h3>\n",
    "<p>The notebook below takes the Covid-19 df and prepares it to use in Deep Learning Notebooks</p>\n",
    "<br>\n",
    "<p>The raw data consists of the following feature</p>\n",
    "<ol>\n",
    "    <li>dateRep</li>\n",
    "    <li style=\"color:red;\">day</li>\n",
    "    <li style=\"color:red;\">month</li>\n",
    "    <li style=\"color:red;\">year</li>\n",
    "    <li>cases</li>\n",
    "    <li>deaths</li>\n",
    "    <li>countriesAndTerritories</li>\n",
    "    <li style=\"color:red;\">geoId</li>\n",
    "    <li style=\"color:red;\">countryterritorycode</li>\n",
    "    <li>popData2018</li>\n",
    "    <li>continentExp</li>\n",
    "</ol>\n",
    "<br>\n",
    "</p>Feature names in red will be remove as they were defined as adding little information to the model. The remaining feautures will be evaluated through the notebook below.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Import dependancies</h5>\n",
    "<ul>\n",
    "    <li>pandas: feature extrapolation and extraction and creation</li>\n",
    "    <li>numpy: numerical data manipluation</li>\n",
    "    <li>os: interaction with the operating system</li>\n",
    "    <li>seaborn: plotting library</li>\n",
    "    <li>sklearn.model_selection.train_test_split: spliting the data into the various data sets (train, test and validation)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</h2>Read in raw data</h2>\n",
    "\n",
    "<p>Change to the relevant directory and read in the csv</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv will need some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(os.getcwd(), 'Datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now read the file. No Line should need skipping.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateRep</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>countriesAndTerritories</th>\n",
       "      <th>geoId</th>\n",
       "      <th>countryterritoryCode</th>\n",
       "      <th>popData2019</th>\n",
       "      <th>continentExp</th>\n",
       "      <th>Cumulative_number_for_14_days_of_COVID-19_cases_per_100000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20/08/2020</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>2020</td>\n",
       "      <td>160</td>\n",
       "      <td>8</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>38041757.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>2.268560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19/08/2020</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>38041757.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>2.024092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dateRep  day  month  year  cases  deaths countriesAndTerritories geoId  \\\n",
       "0  20/08/2020   20      8  2020    160       8             Afghanistan    AF   \n",
       "1  19/08/2020   19      8  2020      0       0             Afghanistan    AF   \n",
       "\n",
       "  countryterritoryCode  popData2019 continentExp  \\\n",
       "0                  AFG   38041757.0         Asia   \n",
       "1                  AFG   38041757.0         Asia   \n",
       "\n",
       "   Cumulative_number_for_14_days_of_COVID-19_cases_per_100000  \n",
       "0                                           2.268560           \n",
       "1                                           2.024092           "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import and format dataframe\n",
    "covid19_df = pd.read_csv(os.path.join(data_folder, 'COVID-19_Cases_Worldwide_2020_08_21'), engine='python')\n",
    "covid19_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to drop\n",
    "drop_columns = ['geoId', 'day', 'month', 'year', 'countryterritoryCode']\n",
    "# Create a 'datetime' column based on the dates\n",
    "covid19_df['dateRep'] = pd.to_datetime(covid19_df['dateRep'], dayfirst=True)\n",
    "# Drop the columns that add no value\n",
    "covid19_df.drop(columns=drop_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the table by the date\n",
    "covid19_df.sort_values(by=['dateRep'], ascending=True, inplace=True)\n",
    "# Create a cumulative sum of covid cases and deaths\n",
    "covid19_df['Cum_Cases'] = covid19_df.groupby(\"countriesAndTerritories\")['cases'].cumsum()\n",
    "covid19_df['Cum_Deaths'] = covid19_df.groupby(\"countriesAndTerritories\")['deaths'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column for days since x deaths\n",
    "covid19_df['flag'] = np.where(covid19_df['Cum_Cases'] > 100, 1, 0) # calculate globaly as its a true false\n",
    "# groupby again creating a unique dataframe for each country, and applying a cumulative sum to the \"flag\" column\n",
    "covid19_df['flag'] = covid19_df.loc[covid19_df['Cum_Cases'] > 100].groupby(\"countriesAndTerritories\")['flag'].cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We don't want Nan's so we replace them in the next few cells below</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dateRep : 0.0\n",
      "cases : 0.0\n",
      "deaths : 0.0\n",
      "countriesAndTerritories : 0.0\n",
      "popData2019 : 0.001709082169466179\n",
      "continentExp : 0.0\n",
      "Cumulative_number_for_14_days_of_COVID-19_cases_per_100000 : 0.07426496114508506\n",
      "Cum_Cases : 0.0\n",
      "Cum_Deaths : 0.0\n",
      "flag : 0.3319358026010094\n"
     ]
    }
   ],
   "source": [
    "for i in covid19_df.columns:\n",
    "    frac_null = covid19_df[i].isna().sum() /len(covid19_df)\n",
    "    print(i, ':', frac_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['United_States_of_America',\n",
       " 'Brazil',\n",
       " 'Mexico',\n",
       " 'India',\n",
       " 'United_Kingdom',\n",
       " 'Italy',\n",
       " 'France',\n",
       " 'Spain',\n",
       " 'Peru',\n",
       " 'Iran',\n",
       " 'Russia',\n",
       " 'Colombia',\n",
       " 'South_Africa',\n",
       " 'Chile',\n",
       " 'Belgium',\n",
       " 'Germany',\n",
       " 'Canada',\n",
       " 'Indonesia',\n",
       " 'Pakistan',\n",
       " 'Netherlands']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_count = covid19_df.groupby('countriesAndTerritories')['deaths'].sum().sort_values(ascending=False).iloc[:20]\n",
    "top_count = list(top_count.keys())\n",
    "top_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim the dataframe to just the 20 most affected countries\n",
    "covid19_df = covid19_df[covid19_df['countriesAndTerritories'].isin(top_count)]\n",
    "# Fill the empty 'flag' rows\n",
    "covid19_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility_df = pd.read_csv(os.path.join(data_folder, 'Apple_Mobility' , 'applemobilitytrends-2020-08-19.csv'), engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only the country data, drop regional data\n",
    "mobility_df = mobility_df.loc[mobility_df['geo_type'] == 'country/region']\n",
    "# Columns to drop\n",
    "drop_columns = ['alternative_name', 'sub-region', 'country', 'geo_type']\n",
    "# Drop the columns that add no value\n",
    "mobility_df.drop(columns=drop_columns, inplace=True)\n",
    "mob_list = mobility_df.columns.to_list()[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transportation_type</th>\n",
       "      <th>region</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>driving</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>walking</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transportation_type   region   variable  value\n",
       "0             driving  Albania 2020-01-13  100.0\n",
       "1             walking  Albania 2020-01-13  100.0"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobility_df = mobility_df.melt(id_vars=['transportation_type', 'region'])\n",
    "# Format the strings so the countries match\n",
    "mobility_df = mobility_df.replace(' ', '_', regex=True)\n",
    "mobility_df = mobility_df.replace('United_States', 'United_States_of_America', regex=True)\n",
    "mobility_df = mobility_df.replace('Republic_of_Korea', 'South_Korea', regex=True)\n",
    "# Create a 'datetime' column based on the dates\n",
    "mobility_df['variable'] = pd.to_datetime(mobility_df['variable'], dayfirst=True)\n",
    "mobility_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in top_count1:\n",
    "    country_len = len(country_df_2.loc[(country_df_2['countriesAndTerritories'] == country) & (country_df_2['flag'] > 0)])\n",
    "    blank_df = pd.DataFrame(columns=['driving', 'walking', 'transit', 'region', 'dateRep'], index=np.arange(len(mob_list))\n",
    "    for i in range(len(country_df_mean) - country_len):\n",
    "        date_value_max = pd.DateOffset(i + 1) + country_df_2.loc[(country_df_2['countriesAndTerritories'] == country)]['dateRep'].max()\n",
    "        pop_value = country_df_2.loc[(country_df_2['dateRep'] == (country_df_2.loc[(country_df_2['countriesAndTerritories'] == country)]['dateRep'].max())) & (country_df_2['countriesAndTerritories'] == country)]['popData2018'].iloc[0]\n",
    "        #continentExp_value = country_df_2.loc[(country_df_2['dateRep'] == (country_df_2.loc[(country_df_2['countriesAndTerritories'] == country)]['dateRep'].max())) & (country_df_2['countriesAndTerritories'] == country)]['continentExp'].iloc[0]\n",
    "        deathpred_value = country_df_2.loc[(country_df_2['dateRep'] == (country_df_2.loc[(country_df_2['countriesAndTerritories'] == country)]['dateRep'].max())) & (country_df_2['countriesAndTerritories'] == country)]['5D_MA_deaths'].iloc[0]\n",
    "        #deathpred_value = country_df_2.loc[(country_df_2['dateRep'] == (country_df_2.loc[(country_df_2['countriesAndTerritories'] == country)]['dateRep'].max())) & (country_df_2['countriesAndTerritories'] == country)]['deaths'].iloc[0]\n",
    "        cumprod_value = 1\n",
    "        blank_df = blank_df.append({'flag': (i + country_len + 1), 'countriesAndTerritories': country, 'dateRep': date_value_max, 'popData2018': pop_value, 'cum_7D_MA_deaths_global': 1, '7D_DeathPred': deathpred_value}, ignore_index=True) # 'continentExp': continentExp_value,\n",
    "    country_df_2 = pd.concat([country_df_2, blank_df])\n",
    "country_df_2.loc[country_df_2['countriesAndTerritories'] == 'United_Kingdom'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Estonia',\n",
       " 'Croatia',\n",
       " 'Norway',\n",
       " 'Sweden',\n",
       " 'Finland',\n",
       " 'Denmark',\n",
       " 'Japan',\n",
       " 'Germany',\n",
       " 'Taiwan',\n",
       " 'Slovakia',\n",
       " 'Switzerland',\n",
       " 'Czech_Republic',\n",
       " 'Belgium',\n",
       " 'Canada',\n",
       " 'Netherlands',\n",
       " 'United_States_of_America',\n",
       " 'France',\n",
       " 'Lithuania',\n",
       " 'Latvia',\n",
       " 'Slovenia',\n",
       " 'Italy',\n",
       " 'Ireland',\n",
       " 'Spain',\n",
       " 'United_Kingdom',\n",
       " 'Luxembourg',\n",
       " 'Russia',\n",
       " 'Ukraine',\n",
       " 'New_Zealand',\n",
       " 'Australia',\n",
       " 'Mexico',\n",
       " 'Bulgaria',\n",
       " 'Greece',\n",
       " 'Iceland',\n",
       " 'Poland',\n",
       " 'Brazil',\n",
       " 'Austria',\n",
       " 'Turkey',\n",
       " 'Hungary',\n",
       " 'Vietnam',\n",
       " 'Albania',\n",
       " 'Singapore',\n",
       " 'Romania',\n",
       " 'Portugal',\n",
       " 'Malaysia',\n",
       " 'Egypt',\n",
       " 'Israel',\n",
       " 'Serbia',\n",
       " 'Saudi_Arabia',\n",
       " 'United_Arab_Emirates',\n",
       " 'Thailand',\n",
       " 'Indonesia',\n",
       " 'Colombia',\n",
       " 'Philippines',\n",
       " 'South_Africa',\n",
       " 'Cambodia',\n",
       " 'India',\n",
       " 'South_Korea',\n",
       " 'Morocco',\n",
       " 'Hong_Kong',\n",
       " 'Uruguay',\n",
       " 'Chile',\n",
       " 'Argentina',\n",
       " 'Macao']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_count1 = mobility_df.groupby('region')['value'].sum().sort_values(ascending=False).iloc[:]\n",
    "top_count1 = list(top_count1.keys())\n",
    "top_count1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Level transportation_type not found'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_get_level_number\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m             \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'transportation_type' is not in list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-c617e882b0f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmobility_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transportation_type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'region'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmob_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(self, index, columns, values)\u001b[0m\n\u001b[1;32m   5921\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5923\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5925\u001b[0m     _shared_docs[\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(data, index, columns, values)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mindexed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mindexed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36munstack\u001b[0;34m(self, level, fill_value)\u001b[0m\n\u001b[1;32m   6384\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6386\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6388\u001b[0m     _shared_docs[\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36munstack\u001b[0;34m(obj, level, fill_value)\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;31m# _unstack_multiple only handles MultiIndexes,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;31m# and isn't needed for a single level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_unstack_multiple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36m_unstack_multiple\u001b[0;34m(data, clocs, fill_value)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mclocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_level_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0mrlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mclocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_level_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0mrlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_get_level_number\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Level {level} not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m                 \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Level transportation_type not found'"
     ]
    }
   ],
   "source": [
    "covid_df = covid19_df.merge(mobility_df, left_on['countriesAndTerritories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Above we filtered out countries not in the 'top_count' list</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Below we export the .csv as a master dataframe. We then do the final processing stages for the train and test datasets</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the folder 'data_export' exists and if not create it.\n",
    "folder_create = os.path.exists(os.path.join(data_folder, \"data_export\"))\n",
    "if folder_create is False:\n",
    "    os.mkdir(os.path.join(data_folder, \"data_export\"))\n",
    "# Export the polished dataframe to re-import after modelling.\n",
    "covid19_df.to_csv(os.path.join(data_folder, \"data_export\", \"covid19_df.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'get_dummies' creates a new column for each country that is populated with either a 1 or a 0\n",
    "df_train = pd.get_dummies(data=covid19_df, columns=[\"countriesAndTerritories\"])\n",
    "# df_y is target to predict, in this case 'deaths'\n",
    "df_y = df_train[['deaths', 'dateRep']]\n",
    "# df_train contains the columns we will use to predict 'deaths'\n",
    "df_train.drop(columns=['cases', 'deaths', 'Cum_Cases', 'Cum_Deaths'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(data_folder, \"data\")\n",
    "# Check if the 'data' folder exists, if not create it\n",
    "folder_create = os.path.exists(data_path)\n",
    "if folder_create is False:\n",
    "    os.mkdir(data_path)\n",
    "    # Create 'train' and 'test' folders if the data folder does not exist.\n",
    "    os.mkdir(os.path.join(data_path, \"train\"))\n",
    "    os.mkdir(os.path.join(data_path, \"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of randomly splitting the data we will select a date to test 'blind' from\n",
    "date_slice = '2020-04-23'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split according to the date. 'train'=before date, 'test'=after.\n",
    "X_train = df_train.loc[df_train['dateRep'] < date_slice]\n",
    "X_test = df_train.loc[df_train['dateRep'] >= date_slice]\n",
    "y_train = df_y.loc[df_y['dateRep'] < date_slice]\n",
    "y_test = df_y.loc[df_y['dateRep'] >= date_slice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export these four dataframes for later.\n",
    "X_train.to_csv(os.path.join(data_path, \"train\", \"train_x.csv\"))\n",
    "y_train.to_csv(os.path.join(data_path, \"train\", \"train_y.csv\"))\n",
    "X_test.to_csv(os.path.join(data_path, \"test\", \"test_x.csv\"))\n",
    "y_test.to_csv(os.path.join(data_path, \"test\", \"test_y.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
